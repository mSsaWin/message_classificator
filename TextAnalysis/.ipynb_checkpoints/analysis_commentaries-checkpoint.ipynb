{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16024bf",
   "metadata": {},
   "source": [
    "##### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9023e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint  # сохранение весов\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor # автоматическое отслеживание lr\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping  # ранние остановки\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"FutureWarning\")\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c125453",
   "metadata": {},
   "source": [
    "##### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1f90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_from_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30443cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'data.csv'\n",
    "\n",
    "data = get_file_from_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7adc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3D Touch просто восхитительная вещь! Заряд дер...\n",
       "1         Отключается при температуре близкой к нулю, не...\n",
       "2         В Apple окончательно решили не заморачиваться,...\n",
       "3         Постарался наиболее ёмко и коротко описать все...\n",
       "4         Достойный телефон. Пользоваться одно удовольст...\n",
       "                                ...                        \n",
       "458428    удобный, всё работает отлично, звонит, играет,...\n",
       "458429    прошло больше года, притензий нет, при моей на...\n",
       "458430    мой первый аппарат на андроиде. На данный моме...\n",
       "458431    Разбил iphone и не было желания покупать новый...\n",
       "458432             Очень доволен покупкой и всем советую...\n",
       "Name: Review, Length: 457837, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9fa8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    228086\n",
       "4    106503\n",
       "3     53055\n",
       "2     35705\n",
       "1     34484\n",
       "0         2\n",
       "7         1\n",
       "9         1\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f5c90",
   "metadata": {},
   "source": [
    "##### Уберем нейтральные отзывы и маловстречающиеся оценки -> 0, 3, 7, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e74e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    228086\n",
       "4    106503\n",
       "2     35705\n",
       "1     34484\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "excluded_grades = [0, 3 ,7 ,9]\n",
    "\n",
    "data = data[~data.Rating.isin(excluded_grades)]\n",
    "\n",
    "data['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eca2e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Touch просто восхитительная вещь! Заряд дер...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Отключается при температуре близкой к нулю, не...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Постарался наиболее ёмко и коротко описать все...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Достойный телефон. Пользоваться одно удовольст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6s gold 64gb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458428</th>\n",
       "      <td>удобный, всё работает отлично, звонит, играет,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458429</th>\n",
       "      <td>прошло больше года, притензий нет, при моей на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458430</th>\n",
       "      <td>мой первый аппарат на андроиде. На данный моме...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458431</th>\n",
       "      <td>Разбил iphone и не было желания покупать новый...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458432</th>\n",
       "      <td>Очень доволен покупкой и всем советую...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  sentiment\n",
       "0       3D Touch просто восхитительная вещь! Заряд дер...          1\n",
       "1       Отключается при температуре близкой к нулю, не...          1\n",
       "3       Постарался наиболее ёмко и коротко описать все...          1\n",
       "4       Достойный телефон. Пользоваться одно удовольст...          1\n",
       "5                                            6s gold 64gb          1\n",
       "...                                                   ...        ...\n",
       "458428  удобный, всё работает отлично, звонит, играет,...          1\n",
       "458429  прошло больше года, притензий нет, при моей на...          1\n",
       "458430  мой первый аппарат на андроиде. На данный моме...          1\n",
       "458431  Разбил iphone и не было желания покупать новый...          1\n",
       "458432           Очень доволен покупкой и всем советую...          1\n",
       "\n",
       "[404778 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим колонку с оценками на тональность и заменим значения 0 - negative, 1 - positive\n",
    "\n",
    "sentiments_decriptor = { 'negative': 0, 'positive': 1 }\n",
    "\n",
    "data = data.rename(columns={'Rating': 'sentiment'})\n",
    "\n",
    "data.loc[data['sentiment'] <= 2, 'sentiment'] = sentiments_decriptor['negative']\n",
    "data.loc[data['sentiment'] >= 4, 'sentiment'] = sentiments_decriptor['positive']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf11a6",
   "metadata": {},
   "source": [
    "##### Предобработка выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ddb107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20a1b206",
   "metadata": {},
   "source": [
    "##### Определение устройства для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a03b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0850d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# data = get_file_from_csv('small_data.csv')\n",
    "# data.rename(columns={'Review': 'text', 'sentiment': 'label'}, inplace=True)\n",
    "# data\n",
    "# train_data, test_data = train_test_split(data, test_size=0.3)\n",
    "# train_data, val_data = train_test_split(data, test_size=0.3)\n",
    "# # data['sentiment'].value_counts()\n",
    "# train_data = pd.DataFrame(train_data)\n",
    "# test_data = pd.DataFrame(test_data)\n",
    "# val_data = pd.DataFrame(val_data)\n",
    "# train_data['label'].value_counts()\n",
    "# test_data['label'].value_counts()\n",
    "# train_data.to_csv('train.csv', index=False)\n",
    "# test_data.to_csv('test.csv', index=False)\n",
    "# val_data.to_csv('val.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3c92b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SsaWin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "class TextPreproccessor:\n",
    "    def __init__(self):\n",
    "        self.__html_pattern = re.compile(\n",
    "            '<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "        self.__alphabet = \"абвгдежзийклмнопрстуфхцчшщъыьэюя \"\n",
    "\n",
    "        self.__mystem = Mystem()  # for lemmatization\n",
    "        self.__russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "    def __remove_html(self, text: str) -> str:\n",
    "        return re.sub(self.__html_pattern, '', text)\n",
    "\n",
    "    def __filter_symbols(self, text: str) -> str:\n",
    "        return ''.join([symbol for symbol in text if symbol in self.__alphabet])\n",
    "\n",
    "    def __lemmatization(self, text: str) -> str:\n",
    "        return ''.join(self.__mystem.lemmatize(text))\n",
    "\n",
    "    def __strip(self, text: str) -> str:\n",
    "        return text.strip()\n",
    "\n",
    "    def __lower(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def __remove_stopwords(self, text: str) -> str:\n",
    "        words = text.split(' ')\n",
    "\n",
    "        words_without_stopwords = []\n",
    "\n",
    "        for word in words:\n",
    "            if word not in self.__russian_stopwords:\n",
    "                words_without_stopwords.append(word)\n",
    "\n",
    "        return ' '.join(words_without_stopwords)\n",
    "\n",
    "    def preproccess_text(self, text: str) -> str:\n",
    "        text = self.__remove_html(text)\n",
    "        text = self.__lower(text)\n",
    "        text = self.__strip(text)\n",
    "        text = text.replace('ё', 'e')\n",
    "        # text = self.__filter_symbols(text)\n",
    "        text = self.__remove_stopwords(text)\n",
    "        # text = self.__lemmatization(text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4a43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer_path=\"cointegrated/rubert-tiny2\"):\n",
    "        df = self.read_csv(file_path)\n",
    "        \n",
    "        self.texts = df['text'].values.astype(str)\n",
    "        self.labels = df['label'].values.astype(int)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "        self.text_preproccessor = TextPreproccessor()\n",
    "\n",
    "    def read_csv(self, path: str) -> pd.DataFrame:\n",
    "        return pd.read_csv(path).dropna()\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        t = self.tokenizer(text, padding='max_length',\n",
    "                           truncation=True, return_tensors='pt')\n",
    "\n",
    "        input_ids = t['input_ids']\n",
    "        token_type_ids = t['token_type_ids']\n",
    "        attention_mask = t['attention_mask']\n",
    "\n",
    "        return input_ids.squeeze(), token_type_ids.squeeze(), attention_mask.squeeze()\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        text = self.text_preproccessor.preproccess_text(text)\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = self.tokenize(text)\n",
    "\n",
    "        return input_ids, token_type_ids, attention_mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe2db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 batch_size: int = 32,\n",
    "                 data_dir: str = './data/',\n",
    "                 num_workers: int = 4,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_set = CSVDataset(os.path.join(self.data_dir, 'train.csv'))\n",
    "        self.val_set = CSVDataset(os.path.join(self.data_dir, 'val.csv'))\n",
    "        self.test_set = CSVDataset(os.path.join(self.data_dir, 'test.csv'))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset=self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset=self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7e7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticClassifier(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 model=\"cointegrated/rubert-tiny2\",\n",
    "                 out_channels=1,\n",
    "                 dropout=0.25,\n",
    "                 eta=3e-4,\n",
    "                 criterion = None,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model, num_labels=out_channels)\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.criterion = criterion if criterion is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.eta = eta\n",
    "\n",
    "        self.metrics = {'accuracy': Accuracy(task='binary').to(device)}\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        return self.model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0]\n",
    "\n",
    "    def shared_step(self, sample, stage):\n",
    "        \n",
    "        input_ids, token_type_ids, attention_mask, label = sample\n",
    "\n",
    "        logits = self.forward(input_ids, token_type_ids, attention_mask)\n",
    "\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        loss = self.criterion(logits, label)\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'accuracy': self.metrics[\"accuracy\"](preds, label)\n",
    "        }\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        loss = np.mean([x[\"loss\"].item() for x in outputs])\n",
    "        acc = np.mean([x[\"accuracy\"].item() for x in outputs])\n",
    "\n",
    "        metrics = {\n",
    "            f\"{stage}_loss\": loss,\n",
    "            f\"{stage}_acc\": acc\n",
    "        }\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.eta)\n",
    "\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                patience=5\n",
    "            ),\n",
    "            \"interval\": \"epoch\",\n",
    "            \"monitor\": \"valid_loss\"\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler_dict}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, 'train')\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, 'valid')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, 'valid')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, 'test')\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dm = SentenceDataModule(batch_size=BATCH_SIZE)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e4e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SemanticClassifier(\n",
       "  (model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "        (position_embeddings): Embedding(2048, 312)\n",
       "        (token_type_embeddings): Embedding(2, 312)\n",
       "        (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=312, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = SemanticClassifier()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70d804f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath='models',\n",
    "        filename='{epoch}_{valid_acc:.2f}_{valid_loss:.2f}',\n",
    "        save_top_k=2,\n",
    "        monitor='valid_loss',\n",
    "        mode='min'\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    EarlyStopping(\n",
    "        monitor=\"valid_loss\",\n",
    "        min_delta=2e-4,\n",
    "        patience=10,\n",
    "        verbose=False,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "]\n",
    "\n",
    "LOG_PATH = './logs'\n",
    "logger = TensorBoardLogger(LOG_PATH, name='tiny_bert')\n",
    "\n",
    "CHECKPOINT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7fc036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    max_epochs=100,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    "    resume_from_checkpoint=CHECKPOINT,\n",
    "    num_sanity_val_steps=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0ef303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | model     | BertForSequenceClassification | 29.2 M\n",
      "1 | criterion | CrossEntropyLoss              | 0     \n",
      "2 | dropout   | Dropout                       | 0     \n",
      "------------------------------------------------------------\n",
      "29.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.2 M    Total params\n",
      "116.776   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77aad89fa6764051a758c5c6ab19af8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88086e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5355afa84ca9633534ce9b412c10717d9edcb1ff9ccf8f00101414d78fa9f67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
